{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bangkit Capstone.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bangkit-cap0423/Guifena-ML/blob/master/Bangkit_Capstone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy5DXz_MUCEI"
      },
      "source": [
        "!apt install ffmpeg\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIpxWUi1Ubxt"
      },
      "source": [
        "pip install scaper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydklE5K2eKN2"
      },
      "source": [
        "import scaper, os\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVhGiwON3qQt"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0AGho3Q3xC6"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPRjnFMPen1I"
      },
      "source": [
        "os.chdir('drive/MyDrive/audio_alt_path')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t0fwLQjN4mk"
      },
      "source": [
        "# Download from youtube dynamically"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yttdpiEP_nRu"
      },
      "source": [
        "\n",
        "pip install youtube_dl\n",
        "import youtube_dl\n",
        "\n",
        "\n",
        "ydl_opts = {\n",
        "    'format': 'bestaudio/best',\n",
        "    'postprocessors': [{\n",
        "        'key': 'FFmpegExtractAudio',\n",
        "        'preferredcodec': 'wav',\n",
        "        'preferredquality': '192',\n",
        "    }],\n",
        "}\n",
        "linkchainsaw = ['https://www.youtube.com/watch?v=0DzsPL-xElE','https://www.youtube.com/watch?v=1MgcrYdYas0',\n",
        "                'https://www.youtube.com/watch?v=9HcahqYUVoc','https://www.youtube.com/watch?v=AhcY8QVSLtM',\n",
        "                'https://www.youtube.com/watch?v=BBukw6JpCeg','https://www.youtube.com/watch?v=BsYFCAuPjwE', \n",
        "                'https://www.youtube.com/watch?v=C46X66FU_Dw', 'https://www.youtube.com/watch?v=LH08k5Kf4AI', \n",
        "                'https://www.youtube.com/watch?v=NJUl3gPX07o', 'https://www.youtube.com/watch?v=_6uZ1HyHSQY',\n",
        "                'https://www.youtube.com/watch?v=kHNWRR0hJ08','https://www.youtube.com/watch?v=yaaHJV5VOXQ']\n",
        "\n",
        "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "  for link in linkchainsaw:\n",
        "    ydl.download([link])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPK9DmurE78u"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/audio_alt_path')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogYS9EklOPlc"
      },
      "source": [
        "# Generate Dataset Chainsaw sound + Forest Sound"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkC3NvQuE2Nb"
      },
      "source": [
        "import scaper, os\n",
        "soundscape_duration = 30.0\n",
        "outfolder = 'soundscapes/'\n",
        "foreground = os.path.expanduser(\"foreground\")\n",
        "background = os.path.expanduser(\"background\")\n",
        "sc = scaper.Scaper(soundscape_duration, foreground, background)\n",
        "sc.add_background(label=(\"const\", \"forest\"),\n",
        "                 source_file=(\"choose\", []),\n",
        "                 source_time=(\"uniform\", 0, 300-soundscape_duration))\n",
        "\n",
        "for i in range(1000):\n",
        "    audiofile = outfolder+f'/normal_{i}.wav'\n",
        "    jamsfile = outfolder+f'/normal_{i}.jams'\n",
        "    txtfile = outfolder+f'/normal_{i}.txt'\n",
        "    sc.generate(audiofile, jamsfile,\n",
        "                allow_repeated_label=True,\n",
        "                allow_repeated_source=True,\n",
        "                disable_sox_warnings=True,\n",
        "                no_audio=False)\n",
        "    \n",
        "sc.add_event(label=(\"const\", \"chainsaw\"),\n",
        "            source_file=(\"choose\", []),\n",
        "            source_time=(\"uniform\", 10, 30),\n",
        "            event_time=(\"const\", 0),\n",
        "            event_duration=(\"const\", 30),\n",
        "            snr=(\"uniform\", -5, 0),\n",
        "            pitch_shift=(\"uniform\", -15, 15),\n",
        "            time_stretch=None)\n",
        "\n",
        "for i in range(1000):\n",
        "    audiofile = outfolder+f'/soundscape_{i}.wav'\n",
        "    jamsfile = outfolder+f'/soundscape_{i}.jams'\n",
        "    sc.generate(audiofile, jamsfile,\n",
        "                allow_repeated_label=True,\n",
        "                allow_repeated_source=True,\n",
        "                disable_sox_warnings=True,\n",
        "                no_audio=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29f-vkWFOYxT"
      },
      "source": [
        "# Generate Image Dataset (1) Due too Memory Usage, Split into 2\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogbt_qEmEuzy"
      },
      "source": [
        "import librosa.display, os, gc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def extract_spectrogram(fname, iname):\n",
        "    audio, sr = librosa.load(fname, res_type='kaiser_fast')\n",
        "    S = librosa.feature.melspectrogram(audio, sr=sr, n_mels=128)\n",
        "    log_S = librosa.power_to_db(S, ref=np.max)\n",
        "    fig = plt.figure(figsize=[1, 1])\n",
        "    ax = fig.add_subplot(111)\n",
        "    fig.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
        "    ax.axis(\"off\")\n",
        "    ax.axis(\"tight\")\n",
        "    plt.margins(0)\n",
        "    librosa.display.specshow(log_S, sr=sr)\n",
        "    fig.savefig(iname, dpi=100, pad_inches=0)\n",
        "    plt.close(fig)\n",
        "    plt.close('all')\n",
        "    del audio, S, log_S, ax, fig\n",
        "    \n",
        "samples_folder = \"soundscapes/\"\n",
        "images_folder = \"images/\"\n",
        "already = os.listdir(images_folder)\n",
        "d = os.listdir(samples_folder)\n",
        "for i, f in enumerate(d):\n",
        "    if(f.split('.')[1]=='wav'):\n",
        "      extract_spectrogram(samples_folder+f, f\"{images_folder}/{f.replace('.wav', '.png')}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdC9O7RhOeon"
      },
      "source": [
        "# Generate Image Dataset 2 Due too Memory Usage, Split into 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XINGpQK7fxEl"
      },
      "source": [
        "import librosa.display, os, gc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def extract_spectrogram(fname, iname):\n",
        "    audio, sr = librosa.load(fname, res_type='kaiser_fast')\n",
        "    S = librosa.feature.melspectrogram(audio, sr=sr, n_mels=128)\n",
        "    log_S = librosa.power_to_db(S, ref=np.max)\n",
        "    fig = plt.figure(figsize=[1, 1])\n",
        "    ax = fig.add_subplot(111)\n",
        "    fig.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
        "    ax.axis(\"off\")\n",
        "    ax.axis(\"tight\")\n",
        "    plt.margins(0)\n",
        "    librosa.display.specshow(log_S, sr=sr)\n",
        "    fig.savefig(iname, dpi=100, pad_inches=0)\n",
        "    plt.close(fig)\n",
        "    plt.close('all')\n",
        "    del audio, S, log_S, ax, fig\n",
        "    \n",
        "samples_folder = \"soundscapes/\"\n",
        "images_folder = \"images/\"\n",
        "already = os.listdir(images_folder)\n",
        "d = os.listdir(samples_folder)\n",
        "for i, f in enumerate(d):\n",
        "  name = f.split('.')[0]\n",
        "  tipe,nomor = name.split('_')\n",
        "  print(name)\n",
        "  if(f.split('.')[1]=='wav'):\n",
        "    if(tipe=='soundscape' and int(nomor)>300):\n",
        "      extract_spectrogram(samples_folder+f, f\"{images_folder}/{f.replace('.wav', '.png')}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8G5Lg0SOxIw"
      },
      "source": [
        "# Labeling and Split Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDQO5mJZT8lY"
      },
      "source": [
        " \n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "samples = []\n",
        "labels = []\n",
        "images_folder = \"images/\"\n",
        "for image in os.listdir(images_folder):\n",
        "    samples.append(tf.keras.preprocessing.image.img_to_array(tf.keras.preprocessing.image.load_img(images_folder+image, target_size=(100, 100))))\n",
        "    if \"normal\" in image:\n",
        "        labels.append((0))\n",
        "    else:\n",
        "        labels.append((1))\n",
        "samples = np.array(samples)\n",
        "labels = np.array(labels)\n",
        "eval_x, eval_y = samples[-100:], labels[-100:]\n",
        "print(samples.shape, labels.shape)\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(samples[:-100], labels[:-100], test_size=0.2, random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MH7aYDGOwjF"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgvt9xSXT-ho"
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(100, 100, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "tf.keras.layers.Dense(512, activation='relu'),\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "print(model.summary())\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "history = model.fit(x_train, y_train, batch_size=20, epochs=150,\n",
        "          validation_data=(x_test, y_test),\n",
        "         verbose=1)\n",
        "model.save('model/')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IRCiEug-1lo"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc)\n",
        "plt.plot(epochs, val_acc)\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss)\n",
        "plt.plot(epochs, val_loss)\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "print('Training Accuracy \\t: {}'.format(acc[-1]))\n",
        "print('Validation Accuracy \\t: {}'.format(val_acc[-1]))\n",
        "print('Training Loss \\t\\t: {}'.format(loss[-1]))\n",
        "print('Validation Loss \\t: {}'.format(val_loss[-1]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}